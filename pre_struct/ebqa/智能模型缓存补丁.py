#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
EBQA æ™ºèƒ½æ¨¡å‹ç¼“å­˜è¡¥ä¸ï¼ˆå¸¦è‡ªåŠ¨è¿‡æœŸå’Œå¥åº·æ£€æŸ¥ï¼‰

åŠŸèƒ½ï¼š
1. æ¨¡å‹ç¼“å­˜ï¼ˆé¿å…é‡å¤åŠ è½½ï¼‰
2. è‡ªåŠ¨è¿‡æœŸæ¸…ç†ï¼ˆé•¿æœŸä¸ç”¨è‡ªåŠ¨å¸è½½ï¼‰
3. å¥åº·æ£€æŸ¥ï¼ˆç¡®ä¿æ¨¡å‹æœ‰æ•ˆï¼‰
4. æ‰‹åŠ¨æ¸…ç†æ¥å£

ä½¿ç”¨æ–¹æ³•ï¼š
    python3 æ™ºèƒ½æ¨¡å‹ç¼“å­˜è¡¥ä¸.py

ä½œè€…ï¼šAI Assistant
æ—¥æœŸï¼š2025-10-30
"""

import os
import sys
from pathlib import Path

def apply_smart_cache_patch():
    """åº”ç”¨æ™ºèƒ½æ¨¡å‹ç¼“å­˜è¡¥ä¸"""
    
    script_dir = Path(__file__).parent
    target_file = script_dir / "test_ebqa.py"
    
    if not target_file.exists():
        print(f"âŒ é”™è¯¯ï¼šæ‰¾ä¸åˆ°æ–‡ä»¶ {target_file}")
        sys.exit(1)
    
    # è¯»å–æ–‡ä»¶
    content = target_file.read_text(encoding="utf-8")
    
    # æ£€æŸ¥æ˜¯å¦å·²ç»æœ‰æ™ºèƒ½ç¼“å­˜
    if "ModelCacheEntry" in content:
        print("âœ… æ™ºèƒ½æ¨¡å‹ç¼“å­˜å·²å­˜åœ¨ï¼Œæ— éœ€é‡å¤åº”ç”¨")
        return
    
    # æ£€æŸ¥æ˜¯å¦æœ‰æ—§çš„ç®€å•ç¼“å­˜
    if "_EBQA_MODEL_CACHE" in content:
        print("ğŸ”„ æ£€æµ‹åˆ°æ—§çš„ç®€å•ç¼“å­˜ï¼Œå°†å‡çº§ä¸ºæ™ºèƒ½ç¼“å­˜...")
        # å¤‡ä»½
        backup_file = target_file.with_suffix(".py.backup_smart")
        backup_file.write_text(content, encoding="utf-8")
        print(f"ğŸ“¦ åˆ›å»ºå¤‡ä»½ï¼š{backup_file}")
        
        # åˆ é™¤æ—§çš„ç¼“å­˜ä»£ç 
        lines = content.split('\n')
        new_lines = []
        skip_block = False
        
        for i, line in enumerate(lines):
            # è·³è¿‡æ—§çš„ç¼“å­˜å—
            if "# ==================== æ¨¡å‹ç¼“å­˜æœºåˆ¶ ====================" in line:
                skip_block = True
                continue
            
            if skip_block:
                # æ‰¾åˆ°ç¼“å­˜å—ç»“æŸä½ç½®ï¼ˆç©ºè¡Œåçš„ def load_ebqaï¼‰
                if line.strip().startswith("def load_ebqa"):
                    skip_block = False
                    new_lines.append(line)
                continue
            
            # ä¿®æ”¹ predict_for å‡½æ•°
            if "model, collate, _ = _get_cached_ebqa_model(cfg)" in line:
                line = line.replace("_get_cached_ebqa_model", "_get_smart_cached_model")
            
            new_lines.append(line)
        
        content = '\n'.join(new_lines)
    else:
        # å…¨æ–°æ·»åŠ 
        backup_file = target_file.with_suffix(".py.backup")
        if not backup_file.exists():
            backup_file.write_text(content, encoding="utf-8")
            print(f"ğŸ“¦ åˆ›å»ºå¤‡ä»½ï¼š{backup_file}")
    
    # æ™ºèƒ½ç¼“å­˜ä»£ç 
    smart_cache_code = '''
# ==================== æ™ºèƒ½æ¨¡å‹ç¼“å­˜æœºåˆ¶ ====================
# æ·»åŠ æ—¥æœŸï¼š2025-10-30
# åŠŸèƒ½ï¼šè‡ªåŠ¨è¿‡æœŸæ¸…ç† + å¥åº·æ£€æŸ¥
import time
import threading
from dataclasses import dataclass
from typing import Optional, Tuple


@dataclass
class ModelCacheEntry:
    """æ¨¡å‹ç¼“å­˜æ¡ç›®"""
    model: Any
    collate: Any
    device: Any
    last_access_time: float
    cache_key: Tuple


# å…¨å±€ç¼“å­˜
_EBQA_MODEL_CACHE = {}
_cache_lock = threading.Lock()

# é…ç½®ï¼ˆå¯é€šè¿‡ç¯å¢ƒå˜é‡è°ƒæ•´ï¼‰
CACHE_TTL_SECONDS = int(os.environ.get("EBQA_MODEL_CACHE_TTL", "1800"))  # é»˜è®¤30åˆ†é’Ÿ
AUTO_CLEANUP_INTERVAL = int(os.environ.get("EBQA_CACHE_CLEANUP_INTERVAL", "300"))  # 5åˆ†é’Ÿæ£€æŸ¥ä¸€æ¬¡


def _check_model_health(entry: ModelCacheEntry) -> bool:
    """æ£€æŸ¥æ¨¡å‹æ˜¯å¦å¥åº·ï¼ˆæ˜¯å¦è¿˜åœ¨å†…å­˜/GPUä¸­ï¼‰"""
    try:
        # æ£€æŸ¥æ¨¡å‹æ˜¯å¦è¿˜åœ¨è®¾å¤‡ä¸Š
        if hasattr(entry.model, 'model'):
            device = next(entry.model.model.parameters()).device
            return device == entry.device
        return True
    except Exception as e:
        logger = _get_logger()
        logger.warning(f"[ModelCache] å¥åº·æ£€æŸ¥å¤±è´¥: {e}")
        return False


def _cleanup_expired_cache():
    """æ¸…ç†è¿‡æœŸçš„ç¼“å­˜"""
    with _cache_lock:
        now = time.time()
        expired_keys = []
        
        for key, entry in _EBQA_MODEL_CACHE.items():
            # æ£€æŸ¥æ˜¯å¦è¿‡æœŸ
            if now - entry.last_access_time > CACHE_TTL_SECONDS:
                expired_keys.append(key)
            # æ£€æŸ¥å¥åº·çŠ¶æ€
            elif not _check_model_health(entry):
                expired_keys.append(key)
        
        if expired_keys:
            logger = _get_logger()
            for key in expired_keys:
                logger.info(f"[ModelCache] æ¸…ç†è¿‡æœŸ/æ— æ•ˆç¼“å­˜: {key[:2]}...")
                del _EBQA_MODEL_CACHE[key]
                
                # å°è¯•æ¸…ç† GPU æ˜¾å­˜
                try:
                    import torch
                    if torch.cuda.is_available():
                        torch.cuda.empty_cache()
                except Exception:
                    pass
            
            logger.info(f"[ModelCache] å·²æ¸…ç† {len(expired_keys)} ä¸ªç¼“å­˜æ¡ç›®")


# åå°æ¸…ç†çº¿ç¨‹
_cleanup_thread = None
_cleanup_running = False


def _start_auto_cleanup():
    """å¯åŠ¨è‡ªåŠ¨æ¸…ç†çº¿ç¨‹"""
    global _cleanup_thread, _cleanup_running
    
    if _cleanup_thread is not None and _cleanup_thread.is_alive():
        return
    
    def cleanup_worker():
        logger = _get_logger()
        logger.info(f"[ModelCache] å¯åŠ¨è‡ªåŠ¨æ¸…ç†çº¿ç¨‹ï¼ˆTTL={CACHE_TTL_SECONDS}ç§’ï¼Œæ£€æŸ¥é—´éš”={AUTO_CLEANUP_INTERVAL}ç§’ï¼‰")
        
        while _cleanup_running:
            time.sleep(AUTO_CLEANUP_INTERVAL)
            _cleanup_expired_cache()
    
    _cleanup_running = True
    _cleanup_thread = threading.Thread(target=cleanup_worker, daemon=True)
    _cleanup_thread.start()


def _get_smart_cached_model(cfg: PredictConfig):
    """è·å–ç¼“å­˜çš„æ¨¡å‹ï¼ˆæ™ºèƒ½ç‰ˆæœ¬ï¼Œå¸¦è¿‡æœŸå’Œå¥åº·æ£€æŸ¥ï¼‰
    
    Args:
        cfg: é¢„æµ‹é…ç½®
        
    Returns:
        (model, collate, device): ç¼“å­˜çš„æ¨¡å‹ã€collator å’Œè®¾å¤‡
    """
    cache_key = (
        cfg.model_dir,
        cfg.tokenizer_name,
        cfg.batch_size,
        cfg.max_seq_len,
    )
    
    logger = _get_logger()
    
    with _cache_lock:
        # æ£€æŸ¥ç¼“å­˜æ˜¯å¦å­˜åœ¨ä¸”æœ‰æ•ˆ
        if cache_key in _EBQA_MODEL_CACHE:
            entry = _EBQA_MODEL_CACHE[cache_key]
            
            # å¥åº·æ£€æŸ¥
            if _check_model_health(entry):
                # æ›´æ–°è®¿é—®æ—¶é—´
                entry.last_access_time = time.time()
                logger.info(f"[ModelCache] âœ… ä½¿ç”¨ç¼“å­˜æ¨¡å‹ï¼ˆä¸Šæ¬¡è®¿é—®ï¼š{int(time.time() - entry.last_access_time)}ç§’å‰ï¼‰")
                return entry.model, entry.collate, entry.device
            else:
                # å¥åº·æ£€æŸ¥å¤±è´¥ï¼Œåˆ é™¤ç¼“å­˜
                logger.warning(f"[ModelCache] âš ï¸ ç¼“å­˜æ¨¡å‹æ— æ•ˆï¼Œé‡æ–°åŠ è½½")
                del _EBQA_MODEL_CACHE[cache_key]
        
        # ç¼“å­˜ä¸å­˜åœ¨æˆ–æ— æ•ˆï¼Œé‡æ–°åŠ è½½
        logger.info(f"[ModelCache] é¦–æ¬¡åŠ è½½æ¨¡å‹: {cfg.model_dir}")
        model, collate, device = load_ebqa(cfg)
        
        # åˆ›å»ºç¼“å­˜æ¡ç›®
        entry = ModelCacheEntry(
            model=model,
            collate=collate,
            device=device,
            last_access_time=time.time(),
            cache_key=cache_key
        )
        
        _EBQA_MODEL_CACHE[cache_key] = entry
        logger.info(f"[ModelCache] æ¨¡å‹å·²ç¼“å­˜ï¼ˆTTL={CACHE_TTL_SECONDS}ç§’ï¼‰")
        
        # ç¡®ä¿æ¸…ç†çº¿ç¨‹è¿è¡Œ
        _start_auto_cleanup()
        
        return model, collate, device


def clear_ebqa_model_cache():
    """æ‰‹åŠ¨æ¸…ç†æ‰€æœ‰æ¨¡å‹ç¼“å­˜"""
    global _cleanup_running
    
    with _cache_lock:
        logger = _get_logger()
        count = len(_EBQA_MODEL_CACHE)
        
        if count > 0:
            logger.info(f"[ModelCache] æ‰‹åŠ¨æ¸…ç† {count} ä¸ªç¼“å­˜æ¨¡å‹")
            _EBQA_MODEL_CACHE.clear()
            
            # æ¸…ç† GPU æ˜¾å­˜
            try:
                import torch
                if torch.cuda.is_available():
                    torch.cuda.empty_cache()
                    logger.info("[ModelCache] GPU æ˜¾å­˜å·²æ¸…ç†")
            except Exception as e:
                logger.warning(f"[ModelCache] GPU æ˜¾å­˜æ¸…ç†å¤±è´¥: {e}")
        
        # åœæ­¢æ¸…ç†çº¿ç¨‹
        _cleanup_running = False


def get_cache_info():
    """è·å–ç¼“å­˜ä¿¡æ¯"""
    with _cache_lock:
        now = time.time()
        cache_details = []
        
        for key, entry in _EBQA_MODEL_CACHE.items():
            idle_time = int(now - entry.last_access_time)
            ttl_remaining = max(0, CACHE_TTL_SECONDS - idle_time)
            cache_details.append({
                "key": str(key[:2]),
                "idle_seconds": idle_time,
                "ttl_remaining": ttl_remaining,
                "healthy": _check_model_health(entry)
            })
        
        return {
            "cached_models": len(_EBQA_MODEL_CACHE),
            "ttl_seconds": CACHE_TTL_SECONDS,
            "auto_cleanup_running": _cleanup_running,
            "details": cache_details
        }


'''
    
    # æŸ¥æ‰¾æ’å…¥ä½ç½®ï¼ˆåœ¨ load_ebqa ä¹‹å‰ï¼‰
    load_ebqa_marker = "def load_ebqa(cfg: PredictConfig):"
    if load_ebqa_marker in content:
        content = content.replace(load_ebqa_marker, smart_cache_code + load_ebqa_marker)
    else:
        print("âŒ é”™è¯¯ï¼šæ‰¾ä¸åˆ° load_ebqa å‡½æ•°")
        sys.exit(1)
    
    # ä¿®æ”¹ predict_for ä½¿ç”¨æ–°çš„ç¼“å­˜å‡½æ•°
    content = content.replace(
        "model, collate, _ = load_ebqa(cfg)",
        "model, collate, _ = _get_smart_cached_model(cfg)"
    ).replace(
        "model, collate, _ = _get_cached_ebqa_model(cfg)",
        "model, collate, _ = _get_smart_cached_model(cfg)"
    )
    
    # å†™å›æ–‡ä»¶
    target_file.write_text(content, encoding="utf-8")
    
    print(f"\n{'='*70}")
    print("âœ… æ™ºèƒ½æ¨¡å‹ç¼“å­˜è¡¥ä¸åº”ç”¨æˆåŠŸï¼")
    print(f"{'='*70}")
    print(f"\nğŸ¯ æ–°åŠŸèƒ½ï¼š")
    print(f"  âœ… è‡ªåŠ¨è¿‡æœŸï¼š1800ç§’ï¼ˆ30åˆ†é’Ÿï¼‰æ— è®¿é—®è‡ªåŠ¨å¸è½½")
    print(f"  âœ… å¥åº·æ£€æŸ¥ï¼šç¡®ä¿æ¨¡å‹åœ¨å†…å­˜/GPUä¸­æœ‰æ•ˆ")
    print(f"  âœ… åå°æ¸…ç†ï¼šæ¯300ç§’è‡ªåŠ¨æ£€æŸ¥è¿‡æœŸç¼“å­˜")
    print(f"  âœ… æ‰‹åŠ¨æ¸…ç†ï¼šè°ƒç”¨ clear_ebqa_model_cache() ç«‹å³æ¸…ç†")
    print(f"\nğŸ“ ç¯å¢ƒå˜é‡é…ç½®ï¼ˆå¯é€‰ï¼‰ï¼š")
    print(f"  export EBQA_MODEL_CACHE_TTL=1800      # ç¼“å­˜è¿‡æœŸæ—¶é—´ï¼ˆç§’ï¼‰")
    print(f"  export EBQA_CACHE_CLEANUP_INTERVAL=300 # æ¸…ç†æ£€æŸ¥é—´éš”ï¼ˆç§’ï¼‰")
    print(f"\nğŸ“Š æŸ¥çœ‹ç¼“å­˜çŠ¶æ€ï¼š")
    print(f"  from test_ebqa import get_cache_info")
    print(f"  print(get_cache_info())")
    print(f"\n{'='*70}\n")


if __name__ == "__main__":
    try:
        apply_smart_cache_patch()
    except KeyboardInterrupt:
        print("\nâŒ ç”¨æˆ·ä¸­æ–­æ“ä½œ")
        sys.exit(1)
    except Exception as e:
        print(f"\nâŒ é”™è¯¯ï¼š{e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)

