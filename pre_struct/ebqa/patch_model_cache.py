#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
EBQA æ¨¡å‹ç¼“å­˜è¡¥ä¸
ç”¨é€”ï¼šä¸º test_ebqa.py æ·»åŠ æ¨¡å‹ç¼“å­˜æœºåˆ¶ï¼Œè§£å†³é«˜å¹¶å‘ä¸‹è¿”å› None çš„é—®é¢˜

ä½¿ç”¨æ–¹æ³•ï¼š
    python patch_model_cache.py

ä½œè€…ï¼šAI Assistant
æ—¥æœŸï¼š2025-10-30
"""

import os
import sys
from pathlib import Path

def apply_patch():
    """åº”ç”¨æ¨¡å‹ç¼“å­˜è¡¥ä¸åˆ° test_ebqa.py"""
    
    # å®šä½ test_ebqa.py æ–‡ä»¶
    script_dir = Path(__file__).parent
    target_file = script_dir / "test_ebqa.py"
    
    if not target_file.exists():
        print(f"âŒ é”™è¯¯ï¼šæ‰¾ä¸åˆ°æ–‡ä»¶ {target_file}")
        sys.exit(1)
    
    # å¤‡ä»½åŸæ–‡ä»¶
    backup_file = target_file.with_suffix(".py.backup")
    if not backup_file.exists():
        print(f"ğŸ“¦ åˆ›å»ºå¤‡ä»½ï¼š{backup_file}")
        backup_file.write_text(target_file.read_text(encoding="utf-8"), encoding="utf-8")
    else:
        print(f"âš ï¸  å¤‡ä»½æ–‡ä»¶å·²å­˜åœ¨ï¼š{backup_file}")
    
    # è¯»å–åŸæ–‡ä»¶
    content = target_file.read_text(encoding="utf-8")
    
    # æ£€æŸ¥æ˜¯å¦å·²ç»æ‰“è¿‡è¡¥ä¸
    if "_EBQA_MODEL_CACHE" in content:
        print("âœ… æ¨¡å‹ç¼“å­˜è¡¥ä¸å·²å­˜åœ¨ï¼Œæ— éœ€é‡å¤åº”ç”¨")
        return
    
    print("ğŸ”§ æ­£åœ¨åº”ç”¨æ¨¡å‹ç¼“å­˜è¡¥ä¸...")
    
    # æŸ¥æ‰¾ load_ebqa å‡½æ•°çš„ä½ç½®
    load_ebqa_marker = "def load_ebqa(cfg: PredictConfig):"
    if load_ebqa_marker not in content:
        print(f"âŒ é”™è¯¯ï¼šæ‰¾ä¸åˆ° 'load_ebqa' å‡½æ•°")
        sys.exit(1)
    
    # åœ¨ load_ebqa å‡½æ•°ä¹‹å‰æ’å…¥ç¼“å­˜ä»£ç 
    cache_code = '''
# ==================== æ¨¡å‹ç¼“å­˜æœºåˆ¶ ====================
# æ·»åŠ æ—¥æœŸï¼š2025-10-30
# ç”¨é€”ï¼šé¿å…æ¯æ¬¡è¯·æ±‚é‡æ–°åŠ è½½æ¨¡å‹ï¼Œè§£å†³é«˜å¹¶å‘æ€§èƒ½é—®é¢˜
_EBQA_MODEL_CACHE = {}


def _get_cached_ebqa_model(cfg: PredictConfig):
    """è·å–ç¼“å­˜çš„ EBQA æ¨¡å‹ï¼Œé¿å…é‡å¤åŠ è½½
    
    Args:
        cfg: é¢„æµ‹é…ç½®
        
    Returns:
        (model, collate, device): ç¼“å­˜çš„æ¨¡å‹ã€collator å’Œè®¾å¤‡
    """
    cache_key = (
        cfg.model_dir,
        cfg.tokenizer_name,
        cfg.batch_size,
        cfg.max_seq_len,
    )
    
    if cache_key not in _EBQA_MODEL_CACHE:
        logger = _get_logger()
        logger.info(f"[ModelCache] é¦–æ¬¡åŠ è½½æ¨¡å‹: {cfg.model_dir}")
        model, collate, device = load_ebqa(cfg)
        _EBQA_MODEL_CACHE[cache_key] = (model, collate, device)
        logger.info(f"[ModelCache] æ¨¡å‹å·²ç¼“å­˜ï¼Œcache_key={cache_key[:2]}...")
    else:
        logger = _get_logger()
        logger.info(f"[ModelCache] âœ… ä½¿ç”¨ç¼“å­˜æ¨¡å‹ï¼Œè·³è¿‡é‡å¤åŠ è½½")
    
    return _EBQA_MODEL_CACHE[cache_key]


def clear_ebqa_model_cache():
    """æ¸…ç†æ¨¡å‹ç¼“å­˜ï¼Œé‡Šæ”¾ GPU æ˜¾å­˜"""
    global _EBQA_MODEL_CACHE
    logger = _get_logger()
    logger.info(f"[ModelCache] æ¸…ç† {len(_EBQA_MODEL_CACHE)} ä¸ªç¼“å­˜æ¨¡å‹")
    _EBQA_MODEL_CACHE.clear()


def get_cache_info():
    """è·å–ç¼“å­˜ä¿¡æ¯"""
    return {
        "cached_models": len(_EBQA_MODEL_CACHE),
        "cache_keys": [str(k[:2]) for k in _EBQA_MODEL_CACHE.keys()]
    }


'''
    
    # æ’å…¥ç¼“å­˜ä»£ç 
    content = content.replace(
        load_ebqa_marker,
        cache_code + load_ebqa_marker
    )
    
    # ä¿®æ”¹ predict_for å‡½æ•°ï¼Œä½¿ç”¨ç¼“å­˜æ¨¡å‹
    old_predict_for = '''def predict_for(
    report_title: str, report_text: str, cfg: Optional[PredictConfig] = None
):
    if cfg is None:
        cfg = PredictConfig()
    model, collate, _ = load_ebqa(cfg)
    return predict_one(cfg, model, collate, report_title, report_text)'''
    
    new_predict_for = '''def predict_for(
    report_title: str, report_text: str, cfg: Optional[PredictConfig] = None
):
    """ä½¿ç”¨ç¼“å­˜æ¨¡å‹è¿›è¡Œé¢„æµ‹ï¼Œé¿å…é‡å¤åŠ è½½ï¼ˆå·²ä¼˜åŒ–ï¼‰"""
    if cfg is None:
        cfg = PredictConfig()
    # âœ… ä½¿ç”¨ç¼“å­˜æ¨¡å‹ï¼Œè€Œä¸æ˜¯æ¯æ¬¡é‡æ–°åŠ è½½
    model, collate, _ = _get_cached_ebqa_model(cfg)
    return predict_one(cfg, model, collate, report_title, report_text)'''
    
    if old_predict_for in content:
        content = content.replace(old_predict_for, new_predict_for)
        print("âœ… å·²ä¿®æ”¹ predict_for å‡½æ•°ï¼Œä½¿ç”¨æ¨¡å‹ç¼“å­˜")
    else:
        print("âš ï¸  è­¦å‘Šï¼šæœªæ‰¾åˆ°é¢„æœŸçš„ predict_for å‡½æ•°ï¼Œå¯èƒ½éœ€è¦æ‰‹åŠ¨ä¿®æ”¹")
    
    # å†™å›æ–‡ä»¶
    target_file.write_text(content, encoding="utf-8")
    
    print(f"\n{'='*60}")
    print("âœ… æ¨¡å‹ç¼“å­˜è¡¥ä¸åº”ç”¨æˆåŠŸï¼")
    print(f"{'='*60}")
    print(f"ğŸ“ åŸæ–‡ä»¶å¤‡ä»½ï¼š{backup_file}")
    print(f"ğŸ“ ä¿®æ”¹æ–‡ä»¶ï¼š{target_file}")
    print(f"\nğŸ¯ é¢„æœŸæ•ˆæœï¼š")
    print(f"  - é¦–æ¬¡è¯·æ±‚ï¼š5-10 ç§’ï¼ˆåŠ è½½æ¨¡å‹ï¼‰")
    print(f"  - åç»­è¯·æ±‚ï¼š0.7-30 ç§’ï¼ˆçº¯æ¨ç†ï¼Œæå‡ 50-80%ï¼‰")
    print(f"  - GPU æ˜¾å­˜ï¼šç¨³å®šå ç”¨ï¼Œä¸å†é‡å¤åŠ è½½")
    print(f"  - å¹¶å‘å®‰å…¨æ€§ï¼šå¤§å¹…æå‡")
    print(f"\nğŸ“‹ ä¸‹ä¸€æ­¥ï¼š")
    print(f"  1. é‡æ–°æ„å»º Docker é•œåƒï¼šdocker build -t ebqa-run:latest .")
    print(f"  2. é‡å¯æœåŠ¡ï¼šdocker compose down && docker compose up -d")
    print(f"  3. æŸ¥çœ‹æ—¥å¿—éªŒè¯ï¼šdocker logs -f ebqa-run | grep ModelCache")
    print(f"{'='*60}\n")


if __name__ == "__main__":
    try:
        apply_patch()
    except KeyboardInterrupt:
        print("\nâŒ ç”¨æˆ·ä¸­æ–­æ“ä½œ")
        sys.exit(1)
    except Exception as e:
        print(f"\nâŒ é”™è¯¯ï¼š{e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)

